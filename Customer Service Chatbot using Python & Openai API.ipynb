{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZsmdM0NY92Y"
      },
      "source": [
        "#Task 1: Import Libraries and Define the OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbalTS5Wp4X",
        "outputId": "b470c452-b717-4851-ec4d-628ebefe450e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ],
      "source": [
        "# ! pip install openai\n",
        "! pip install openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKePH20SW5aA",
        "outputId": "916ac484-e3d3-47b6-a3f5-6655a343d40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m862.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "! pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IwaIzzF4WsDT"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# go to \"https://platform.openai.com/api-keys\" to get your api key\n",
        "\n",
        "# Define OpenAI API key\n",
        "openai.api_key = \"api key\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMBxHl5afnho"
      },
      "source": [
        "#Task 2: Chat with ChatGPT using the API key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_gpt(message):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",  # Use the latest model\n",
        "            messages=[{\"role\": \"system\", \"content\": \"You are ChatGPT.\"}, {\"role\": \"user\", \"content\": message}],\n",
        "            max_tokens=50  # Adjust this based on your desired response length\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except openai.error.OpenAIError as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Start a conversation\n",
        "conversation = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    conversation.append(f\"You: {user_input}\")\n",
        "\n",
        "    # Exit the loop if the user wants to end the conversation\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Generate a response from ChatGPT\n",
        "    response = chat_with_gpt(\"\\n\".join(conversation))\n",
        "    print(f\"ChatGPT: {response}\")\n",
        "    conversation.append(f\"ChatGPT: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWNgEVKPawSp",
        "outputId": "abac1bdc-f990-4436-9d91-a95d36305182"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hey\n",
            "ChatGPT: Hello! How can I assist you today?\n",
            "You: data science\n",
            "ChatGPT: Sure! Data Science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It combines statistics, data analysis, machine learning, and their related methods to understand and\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUu9y6EzZSKl"
      },
      "source": [
        "#Task 3: Define the Chatbot Conversation Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l9wn1GojXHIt"
      },
      "outputs": [],
      "source": [
        "def chatbot_conversation(initial_prompt):\n",
        "    # Initialize conversation with initial prompt\n",
        "    prompt = initial_prompt\n",
        "\n",
        "    # Continuously interact with the user until they end the conversation\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        # Send user input and current prompt to ChatGPT API and receive response\n",
        "        response = openai.Completion.create(\n",
        "            model=\"gpt-3.5-turbo\", # this model is specifically designed to understand and generate natural language text (instruction-following tasks)\n",
        "            prompt=prompt + \"\\nUser: \" + user_input,\n",
        "            temperature= 0.7, ### insert the temperature here ###\n",
        "            max_tokens= 1024 ### insert the max number tokens here ###\n",
        "        )\n",
        "\n",
        "        # Extract and display ChatGPT's response\n",
        "        chatbot_response = response.choices[0].text\n",
        "        print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "        # Update prompt for next iteration\n",
        "        prompt = prompt + \"\\nChatbot: \" + chatbot_response + \"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhfcrzXjZXFD"
      },
      "source": [
        "#Task 4: Handle Frequently Asked Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hje9d3v9i1g8"
      },
      "source": [
        "###Handling FAQs for Product Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2y0Tvm6vXJmr"
      },
      "outputs": [],
      "source": [
        "def product_information_faq(user_input):\n",
        "    # Identify product-related keywords in user input\n",
        "    product_keywords = [\"product\", \"item\", \"details\", \"features\", \"specifications\", \"capabilities\"] ### insert product keywords here ###\n",
        "    for keyword in product_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant product information based on user's query\n",
        "            print(\"Please specify the product you're interested in and I'll provide more details.\")\n",
        "            product_name = input(\"Product name: \")\n",
        "            # Use product_name to retrieve and display product information from a database or API\n",
        "            print(\"Product information for \" + product_name + \":\")\n",
        "            # Display product details, features, and specifications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5fWR3z9ZcEU"
      },
      "source": [
        "###Handling FAQs for Shipping and Returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5t0fDzC3XMCd"
      },
      "outputs": [],
      "source": [
        "def shipping_and_returns_faq(user_input):\n",
        "    # Identify shipping or returns keywords in user input\n",
        "    shipping_keywords = [\"shipping\", \"delivery\", \"courier\", \"timeline\"] ### insert product keywords here ###\n",
        "    returns_keywords = [\"return\", \"refund\", \"exchange\", \"policy\"]\n",
        "\n",
        "    for keyword in shipping_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant shipping information based on user's query\n",
        "            print(\"Shipping options and timelines for your order:\")\n",
        "            # Display shipping options, delivery timelines, and estimated delivery dates\n",
        "\n",
        "    for keyword in returns_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant returns information based on user's query\n",
        "            print(\"Our returns policy and procedures:\")\n",
        "            # Display returns policy, return initiation process, and refund or exchange options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjko2N6cZh-Q"
      },
      "source": [
        "###Handling FAQs for Customer Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aNxR3k_UXOSh"
      },
      "outputs": [],
      "source": [
        "def customer_support_faq(user_input):\n",
        "    # Identify customer support keywords in user input\n",
        "    support_keywords = [\"help\", \"issue\", \"problem\", \"assistance\", \"support\"] ### insert product keywords here ###\n",
        "\n",
        "    for keyword in support_keywords:\n",
        "        if keyword in user_input.lower():\n",
        "            # Provide relevant customer support assistance\n",
        "            print(\"Please describe your issue or problem in detail so we can assist you.\")\n",
        "            user_issue = input(\"Description of issue: \")\n",
        "            # Use user_issue to identify and resolve the user's problem or direct them to relevant support resources\n",
        "            print(\"We're here to help. Please provide more details about your issue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5EOYnzgZnFy"
      },
      "source": [
        "#Task 5: Initiate Chatbot Conversation and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "irKGuPtuXQ8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "9f75efb8-9289-4195-e9b2-de624dfb222f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to our customer service chatbot. How can I help you today?\n",
            "User: about products\n",
            "Chatbot: Of course! How can I assist you with information about our products?\n",
            "User: list alll products\n",
            "Chatbot: I'm happy to provide you with information about our products. However, I would need to know the specific category or type of products you are interested in. Could you please provide more details so I can assist you more effectively?\n",
            "User: ebooks\n",
            "Chatbot: We have a wide range of ebooks available across various genres and categories. Our ebooks cover fiction, non-fiction, self-help, business, technology, and many more topics. If you have a specific genre or topic in mind, please let me know so I can provide you with more detailed information.\n",
            "User: list some of them\n",
            "Chatbot: Some popular ebook categories include:\n",
            "\n",
            "1. Fiction (e.g., mystery, romance, science fiction)\n",
            "2. Non-fiction (e.g., biographies, self-help, history)\n",
            "3. Business and entrepreneurship\n",
            "4. Health and wellness\n",
            "5. Cooking and recipes\n",
            "6. Technology and programming\n",
            "7. Travel guides\n",
            "8. Children's books\n",
            "\n",
            "If any of these categories interest you, let me know, and I can recommend some specific ebooks within that genre.\n",
            "User: tell me about tiago\n",
            "Chatbot: I'm not sure which specific Tiago you are referring to. Could you please provide more context or details so I can better assist you?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-44af27d1cb3d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Continuously interact with the user and handle their queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Check if user wants to end the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Function to interact with the ChatGPT model using the Chat API\n",
        "def chat_with_gpt(conversation):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=conversation,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Start the chatbot conversation with a welcome message\n",
        "print(\"Welcome to our customer service chatbot. How can I help you today?\")\n",
        "\n",
        "# Initialize conversation history\n",
        "conversation = [{\"role\": \"system\", \"content\": \"You are a helpful customer service assistant.\"}]\n",
        "\n",
        "# Continuously interact with the user and handle their queries\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # Check if user wants to end the conversation\n",
        "    if user_input.lower() in [\"bye\", \"quit\"]:\n",
        "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Add user input to conversation history\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get ChatGPT's response\n",
        "    chatbot_response = chat_with_gpt(conversation)\n",
        "\n",
        "    # Display ChatGPT's response\n",
        "    print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "    # Add ChatGPT's response to conversation history\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": chatbot_response})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-tSslz4b8df"
      },
      "source": [
        "#Task 6: Build a Customized Chatbot and Chat with It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5OQV8KnyggaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4789c1f6-69af-4f26-df11-4feb26278c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\n",
            "User: what are services provided?\n",
            "Chatbot: I can assist you with a variety of services related to ebooks, including:\n",
            "User: others related to smartphone\n",
            "Chatbot: I can also help you with smartphone-related services such as:\n",
            "User: exit\n",
            "Chatbot: If you have any more questions in the future, feel free to ask. Have a great day!\n",
            "User: bye\n",
            "Thank you for using our chatbot. Have a great day!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Function to interact with the ChatGPT model using the Chat API\n",
        "def chat_with_gpt(conversation):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=conversation,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1500,\n",
        "        stop=[\"\\n\", \" User:\", \" System:\"]\n",
        "    )\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Start the chatbot conversation with a welcome message\n",
        "print(\"Welcome to our ebook customer service chatbot. How can I assist you with your ebook queries today?\")\n",
        "\n",
        "# Initialize conversation history\n",
        "conversation = [{\"role\": \"system\", \"content\": \"You are a customer service AI knowledgeable about ebooks.\"}]\n",
        "\n",
        "# Continuously interact with the user and handle their queries\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # Check if user wants to end the conversation\n",
        "    if user_input.lower() in [\"bye\", \"quit\"]:\n",
        "        print(\"Thank you for using our chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Add user input to conversation history\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get ChatGPT's response\n",
        "    chatbot_response = chat_with_gpt(conversation)\n",
        "\n",
        "    # Check if the user's query is off-topic\n",
        "    if \"ebook\" not in user_input.lower() and \"book\" not in user_input.lower():\n",
        "        keywords = [\"sorry\", \"don't know\", \"not sure\", \"can't help\"]\n",
        "        if any(keyword in chatbot_response.lower() for keyword in keywords):\n",
        "            chatbot_response = \"I'm sorry, I specialize in ebooks. Could you please ask something related to that topic?\"\n",
        "\n",
        "            print(chatbot_response)\n",
        "            continue\n",
        "\n",
        "    # Display ChatGPT's response\n",
        "    print(\"Chatbot:\", chatbot_response)\n",
        "\n",
        "    # Add ChatGPT's response to conversation history\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": chatbot_response})\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}